{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD MODELS TO A TABLE TO DISPLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ToDo \n",
    "1. Add Preprocessing\n",
    "2. Run xgboost for ngram , character ngram\n",
    "3. Doc2Vec\n",
    "4. Add mlogloss as performance metric\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Response</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "      <td>Are there discounts for green energy ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                 Response  \\\n",
       "0    0  Are there discounts for green energy ?   \n",
       "1    1  Are there discounts for green energy ?   \n",
       "2    2  Are there discounts for green energy ?   \n",
       "3    3  Are there discounts for green energy ?   \n",
       "4    4  Are there discounts for green energy ?   \n",
       "\n",
       "                                 Question  \n",
       "0  Are there discounts for green energy ?  \n",
       "1  Are there discounts for green energy ?  \n",
       "2  Are there discounts for green energy ?  \n",
       "3  Are there discounts for green energy ?  \n",
       "4  Are there discounts for green energy ?  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('NLP.xlsx')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Are there discounts for green energy ?': 18,\n",
       "         'What is my balance ?': 1,\n",
       "         'Where do I find my PIN number ?': 9,\n",
       "         'How do I change my mailing address ?': 6,\n",
       "         'How do I stop my service ?': 12,\n",
       "         'what areas do you serve ?': 3,\n",
       "         'How can I see current outages ?': 3})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(df['Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Are there discounts for green energy ?': 11,\n",
       "         'Are they incentives for new thermostat ?': 1,\n",
       "         'Change NC Green Power Contribuition': 1,\n",
       "         'free energy kit': 1,\n",
       "         'free energy saving kit': 1,\n",
       "         'free save energy and water kit': 1,\n",
       "         'free thermostat': 1,\n",
       "         'how to get a free energy savings kit': 1,\n",
       "         'What is my balance ?': 1,\n",
       "         'my pin ?': 1,\n",
       "         'new pin': 1,\n",
       "         'no pin number on bill': 1,\n",
       "         'pin': 1,\n",
       "         'pin location': 1,\n",
       "         'pin number not working': 1,\n",
       "         'there is no pin number on my bill': 1,\n",
       "         'what is a # digit pin ?': 1,\n",
       "         'what is my nine digit pin ?': 1,\n",
       "         'address change': 1,\n",
       "         \"Address doesn't come up for service\": 1,\n",
       "         'Address not found': 1,\n",
       "         'Address to mail bill': 1,\n",
       "         'Address to mail payment': 1,\n",
       "         'Address wrong': 1,\n",
       "         'cancel': 1,\n",
       "         'cancel a stop': 1,\n",
       "         'cancel request to stop service': 1,\n",
       "         'cancel service': 1,\n",
       "         'cancel protection': 1,\n",
       "         'canceling service': 1,\n",
       "         'close account': 1,\n",
       "         'close an account': 1,\n",
       "         'deposit cancel': 1,\n",
       "         'disconect': 1,\n",
       "         'disconnect': 1,\n",
       "         'disconnect power at street': 1,\n",
       "         'why do I not have power': 1,\n",
       "         'why we not have power': 1,\n",
       "         \"why doesn't I have service\": 1,\n",
       "         'Area outages': 1,\n",
       "         'Cancel Outage notification': 1,\n",
       "         'Damaged electronics from power outage': 1})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = list(set(df['Response']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Question']\n",
    "y = df['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8125\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "Are there discounts for green energy ?       0.89      1.00      0.94         8\n",
      "  How do I change my mailing address ?       0.00      0.00      0.00         1\n",
      "                  What is my balance ?       1.00      1.00      1.00         1\n",
      "             what areas do you serve ?       0.50      0.67      0.57         3\n",
      "       Where do I find my PIN number ?       1.00      1.00      1.00         2\n",
      "            How do I stop my service ?       0.00      0.00      0.00         1\n",
      "\n",
      "                           avg / total       0.73      0.81      0.77        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 6, does not match size of target_names, 7\n",
      "  .format(len(labels), len(target_names))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mclf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', MultinomialNB())])\n",
    "\n",
    "mclf.fit(X_train, y_train)\n",
    "y_pred = mclf.predict(X_test)\n",
    "\n",
    "models.append('TfIdf - Multinomial NB')\n",
    "results.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.875\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "Are there discounts for green energy ?       1.00      0.88      0.93         8\n",
      "  How do I change my mailing address ?       0.00      0.00      0.00         1\n",
      "                  What is my balance ?       0.50      1.00      0.67         1\n",
      "             what areas do you serve ?       0.75      1.00      0.86         3\n",
      "       Where do I find my PIN number ?       1.00      1.00      1.00         2\n",
      "            How do I stop my service ?       1.00      1.00      1.00         1\n",
      "\n",
      "                           avg / total       0.86      0.88      0.86        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 6, does not match size of target_names, 7\n",
      "  .format(len(labels), len(target_names))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Linear Algo\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "mclf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', SGDClassifier(loss = 'hinge', penalty = 'l2', alpha=1e-3, random_state=42, max_iter=5, tol=None ))])\n",
    "\n",
    "mclf.fit(X_train, y_train)\n",
    "y_pred = mclf.predict(X_test)\n",
    "\n",
    "models.append('TfIdf - SGD Classifier')\n",
    "results.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9375\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "Are there discounts for green energy ?       1.00      1.00      1.00         8\n",
      "  How do I change my mailing address ?       0.00      0.00      0.00         1\n",
      "                  What is my balance ?       1.00      1.00      1.00         1\n",
      "             what areas do you serve ?       0.75      1.00      0.86         3\n",
      "       Where do I find my PIN number ?       1.00      1.00      1.00         2\n",
      "            How do I stop my service ?       1.00      1.00      1.00         1\n",
      "\n",
      "                           avg / total       0.89      0.94      0.91        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 6, does not match size of target_names, 7\n",
      "  .format(len(labels), len(target_names))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mclf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', LogisticRegression())])\n",
    "\n",
    "mclf.fit(X_train, y_train)\n",
    "y_pred = mclf.predict(X_test)\n",
    "\n",
    "models.append('TfIdf - Logistic Regression')\n",
    "results.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.75\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "Are there discounts for green energy ?       1.00      0.88      0.93         8\n",
      "  How do I change my mailing address ?       0.00      0.00      0.00         1\n",
      "                  What is my balance ?       1.00      1.00      1.00         1\n",
      "             what areas do you serve ?       0.43      1.00      0.60         3\n",
      "       Where do I find my PIN number ?       1.00      0.50      0.67         2\n",
      "            How do I stop my service ?       0.00      0.00      0.00         1\n",
      "\n",
      "                           avg / total       0.77      0.75      0.72        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 6, does not match size of target_names, 7\n",
      "  .format(len(labels), len(target_names))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#n-gram TfIdf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mclf = Pipeline([('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(2,3), max_features=5000)),\n",
    "                ('clf', LogisticRegression())])\n",
    "\n",
    "mclf.fit(X_train, y_train)\n",
    "y_pred = mclf.predict(X_test)\n",
    "\n",
    "models.append('ngram_3-TfIdf - Logistic Regression')\n",
    "results.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.75\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "Are there discounts for green energy ?       1.00      0.88      0.93         8\n",
      "  How do I change my mailing address ?       0.00      0.00      0.00         1\n",
      "                  What is my balance ?       1.00      1.00      1.00         1\n",
      "             what areas do you serve ?       0.43      1.00      0.60         3\n",
      "       Where do I find my PIN number ?       1.00      0.50      0.67         2\n",
      "            How do I stop my service ?       0.00      0.00      0.00         1\n",
      "\n",
      "                           avg / total       0.77      0.75      0.72        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 6, does not match size of target_names, 7\n",
      "  .format(len(labels), len(target_names))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#n-gram TfIdf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mclf = Pipeline([('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(2,4), max_features=5000)),\n",
    "                ('clf', LogisticRegression())])\n",
    "\n",
    "mclf.fit(X_train, y_train)\n",
    "y_pred = mclf.predict(X_test)\n",
    "\n",
    "models.append('ngram_4-TfIdf - Logistic Regression')\n",
    "results.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8125\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "Are there discounts for green energy ?       1.00      0.88      0.93         8\n",
      "  How do I change my mailing address ?       0.00      0.00      0.00         1\n",
      "                  What is my balance ?       1.00      1.00      1.00         1\n",
      "             what areas do you serve ?       0.50      1.00      0.67         3\n",
      "       Where do I find my PIN number ?       1.00      1.00      1.00         2\n",
      "            How do I stop my service ?       0.00      0.00      0.00         1\n",
      "\n",
      "                           avg / total       0.78      0.81      0.78        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 6, does not match size of target_names, 7\n",
      "  .format(len(labels), len(target_names))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#character level ngram\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mclf = Pipeline([('tfidf', TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features=5000)),\n",
    "                ('clf', LogisticRegression())])\n",
    "\n",
    "mclf.fit(X_train, y_train)\n",
    "y_pred = mclf.predict(X_test)\n",
    "\n",
    "models.append('char_ngram_3-TfIdf - Logistic Regression')\n",
    "results.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Are the re discounts for green energy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8125\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "Are there discounts for green energy ?       1.00      0.88      0.93         8\n",
      "  How do I change my mailing address ?       0.00      0.00      0.00         1\n",
      "                  What is my balance ?       1.00      1.00      1.00         1\n",
      "             what areas do you serve ?       0.50      1.00      0.67         3\n",
      "       Where do I find my PIN number ?       1.00      1.00      1.00         2\n",
      "            How do I stop my service ?       0.00      0.00      0.00         1\n",
      "\n",
      "                           avg / total       0.78      0.81      0.78        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 6, does not match size of target_names, 7\n",
      "  .format(len(labels), len(target_names))\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#character level ngram\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mclf = Pipeline([('tfidf', TfidfVectorizer(analyzer='char', ngram_range=(2,4), max_features=5000)),\n",
    "                ('clf', LogisticRegression())])\n",
    "\n",
    "mclf.fit(X_train, y_train)\n",
    "y_pred = mclf.predict(X_test)\n",
    "\n",
    "models.append('char_ngram_4-TfIdf - Logistic Regression')\n",
    "results.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective='multi:softprob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "xgb_model = xgb.XGBClassifier(max_depth=10, learning_rate=0.05, \n",
    "                              colsample_bytree=.7, gamma=0, reg_alpha=4, objective='multi:softmax', \n",
    "                              eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download word2vec\n",
    "#https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "    \n",
    "    if not mean:\n",
    "        return np.zeros(wv.vector_size, )\n",
    "    \n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis = 0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language = 'english'):\n",
    "        for word in nltk.word_tokenize(sent, language = 'english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "train, test = train_test_split(df, test_size = 0.3, random_state = 42)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['Question']), axis = 1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['Question']), axis = 1).values\n",
    "\n",
    "X_train_word_average = word_averaging_list(wv, train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv, test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train_word_average, train['Response'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "\n",
    "models.append('Word2Vec - Logistic Regression')\n",
    "results.append(accuracy_score(y_pred, test.tags))\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, test.tags))\n",
    "print(classification_report(test.tags, y_pred,target_names=res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "\n",
    "train_size = int(len(df) * .7)\n",
    "train_posts = df['Question'][:train_size]\n",
    "train_tags = df['Response'][:train_size]\n",
    "\n",
    "test_posts = df['Question'][train_size:]\n",
    "test_tags = df['Response'][train_size:]\n",
    "\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df['Response'])\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = np.max(encoder.transform(df['Response'])) + 1\n",
    "print(num_classes)\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size = batch_size, verbose = 1)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "models.append('Keras - DL')\n",
    "results.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Keras - DL'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.pop(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8125, 0.875, 0.9375, 0.0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare_Algo = pd.DataFrame({'Models':models, 'Results':results})\n",
    "Compare_Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
